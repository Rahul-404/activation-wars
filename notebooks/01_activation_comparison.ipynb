{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948f235e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81fe908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, PReLU\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, F1Score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 1. Set Python built-in random module seed\n",
    "random.seed(42)\n",
    "\n",
    "# 2. Set NumPy seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# 3. Set TensorFlow seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 4. (Optional) Control environmental sources of randomness\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794f9294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Hands-on DL/activation-wars/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c70b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d01467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Hands-on DL/activation-wars'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e0398",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf88db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(act_config, input_shape=(28, 28, 1)):\n",
    "    layers = []\n",
    "\n",
    "    layers.append(tf.keras.layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    layers.append(act_config if isinstance(act_config, tf.keras.layers.Layer) else tf.keras.layers.Activation(act_config))\n",
    "    \n",
    "    layers.append(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "    layers.append(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    layers.append(act_config if isinstance(act_config, tf.keras.layers.Layer) else tf.keras.layers.Activation(act_config))\n",
    "    \n",
    "    layers.append(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "    layers.append(tf.keras.layers.Flatten())\n",
    "    layers.append(tf.keras.layers.Dense(64))\n",
    "    layers.append(act_config if isinstance(act_config, tf.keras.layers.Layer) else tf.keras.layers.Activation(act_config))\n",
    "    \n",
    "    # Output layer - always softmax for classification\n",
    "    layers.append(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebb1e2",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aea441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess the MNIST data\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.astype(\"float32\") / 255.0\n",
    "# x_test = x_test.astype(\"float32\") / 255.0\n",
    "# y_train = to_categorical(y_train, 10)\n",
    "# y_test = to_categorical(y_test, 10)\n",
    "# y_train_cat = to_categorical(y_train, 10)\n",
    "# y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159ed7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "            'mnist': tf.keras.datasets.mnist,\n",
    "            'fashion_mnist': tf.keras.datasets.fashion_mnist,\n",
    "            'cifar10': tf.keras.datasets.cifar10\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b818b8",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da88c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'sigmoid': 'sigmoid',\n",
    "    'tanh': 'tanh',\n",
    "    'relu': 'relu',\n",
    "    'leaky_relu': tf.keras.layers.LeakyReLU(),\n",
    "    'prelu': tf.keras.layers.PReLU(), # problem with this activation\n",
    "    'elu': 'elu',\n",
    "    'swish': tf.keras.activations.swish,\n",
    "    'swish': tf.keras.layers.Lambda(lambda x: tf.keras.activations.swish(x), name=\"swish_activation\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257a020",
   "metadata": {},
   "source": [
    "## 1. Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7004a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'sigmoid': 'sigmoid',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cef13",
   "metadata": {},
   "source": [
    "### Training: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8b6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-macos-m2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-16 16:00:47.635824: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-05-16 16:00:47.635847: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-05-16 16:00:47.635854: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-05-16 16:00:47.635869: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-16 16:00:47.635882: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 16:00:48.167551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 14s - 15ms/step - accuracy: 0.7175 - loss: 0.8704 - val_accuracy: 0.9450 - val_loss: 0.2043\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9574 - loss: 0.1539 - val_accuracy: 0.9679 - val_loss: 0.1089\n",
      "Epoch 3/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9718 - loss: 0.0966 - val_accuracy: 0.9747 - val_loss: 0.0808\n",
      "Epoch 4/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9786 - loss: 0.0724 - val_accuracy: 0.9792 - val_loss: 0.0642\n",
      "Epoch 5/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9829 - loss: 0.0579 - val_accuracy: 0.9816 - val_loss: 0.0562\n",
      "Epoch 6/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9863 - loss: 0.0478 - val_accuracy: 0.9836 - val_loss: 0.0524\n",
      "Epoch 7/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9885 - loss: 0.0403 - val_accuracy: 0.9840 - val_loss: 0.0509\n",
      "Epoch 8/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9902 - loss: 0.0344 - val_accuracy: 0.9832 - val_loss: 0.0506\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9918 - loss: 0.0294 - val_accuracy: 0.9831 - val_loss: 0.0501\n",
      "Epoch 10/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9933 - loss: 0.0249 - val_accuracy: 0.9835 - val_loss: 0.0485\n",
      "Training on fashion_mnist with sigmoid\n",
      "Epoch 1/10\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.6323 - loss: 1.0083 - val_accuracy: 0.7596 - val_loss: 0.6265\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.7948 - loss: 0.5443 - val_accuracy: 0.8136 - val_loss: 0.5105\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8323 - loss: 0.4567 - val_accuracy: 0.8405 - val_loss: 0.4485\n",
      "Epoch 4/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8495 - loss: 0.4083 - val_accuracy: 0.8490 - val_loss: 0.4162\n",
      "Epoch 5/10\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.8607 - loss: 0.3781 - val_accuracy: 0.8550 - val_loss: 0.3949\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8687 - loss: 0.3548 - val_accuracy: 0.8614 - val_loss: 0.3767\n",
      "Epoch 7/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.8748 - loss: 0.3364 - val_accuracy: 0.8637 - val_loss: 0.3645\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8801 - loss: 0.3211 - val_accuracy: 0.8656 - val_loss: 0.3564\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8852 - loss: 0.3082 - val_accuracy: 0.8672 - val_loss: 0.3498\n",
      "Epoch 10/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.8895 - loss: 0.2964 - val_accuracy: 0.8706 - val_loss: 0.3432\n",
      "Training on cifar10 with sigmoid\n",
      "Epoch 1/10\n",
      "782/782 - 15s - 19ms/step - accuracy: 0.2330 - loss: 2.0792 - val_accuracy: 0.3239 - val_loss: 1.9024\n",
      "Epoch 2/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.3563 - loss: 1.7947 - val_accuracy: 0.4026 - val_loss: 1.6934\n",
      "Epoch 3/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.4155 - loss: 1.6437 - val_accuracy: 0.4385 - val_loss: 1.5853\n",
      "Epoch 4/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.4428 - loss: 1.5603 - val_accuracy: 0.4575 - val_loss: 1.5171\n",
      "Epoch 5/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.4653 - loss: 1.4935 - val_accuracy: 0.4785 - val_loss: 1.4579\n",
      "Epoch 6/10\n",
      "782/782 - 12s - 16ms/step - accuracy: 0.4855 - loss: 1.4333 - val_accuracy: 0.4979 - val_loss: 1.4045\n",
      "Epoch 7/10\n",
      "782/782 - 12s - 16ms/step - accuracy: 0.5063 - loss: 1.3796 - val_accuracy: 0.5137 - val_loss: 1.3605\n",
      "Epoch 8/10\n",
      "782/782 - 12s - 16ms/step - accuracy: 0.5245 - loss: 1.3319 - val_accuracy: 0.5252 - val_loss: 1.3251\n",
      "Epoch 9/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.5410 - loss: 1.2903 - val_accuracy: 0.5374 - val_loss: 1.2967\n",
      "Epoch 10/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.5537 - loss: 1.2530 - val_accuracy: 0.5469 - val_loss: 1.2724\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e90676",
   "metadata": {},
   "source": [
    "## 2. Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e2db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'tanh': 'tanh',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d6c9e",
   "metadata": {},
   "source": [
    "### Training: Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82319365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with tanh\n",
      "Epoch 1/10\n",
      "938/938 - 16s - 17ms/step - accuracy: 0.9522 - loss: 0.1657 - val_accuracy: 0.9802 - val_loss: 0.0659\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9852 - loss: 0.0512 - val_accuracy: 0.9826 - val_loss: 0.0570\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9900 - loss: 0.0348 - val_accuracy: 0.9837 - val_loss: 0.0534\n",
      "Epoch 4/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9938 - loss: 0.0237 - val_accuracy: 0.9859 - val_loss: 0.0443\n",
      "Epoch 5/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9955 - loss: 0.0169 - val_accuracy: 0.9863 - val_loss: 0.0409\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9972 - loss: 0.0122 - val_accuracy: 0.9871 - val_loss: 0.0456\n",
      "Epoch 7/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9970 - loss: 0.0113 - val_accuracy: 0.9890 - val_loss: 0.0394\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9889 - val_loss: 0.0402\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9893 - val_loss: 0.0357\n",
      "Epoch 10/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9879 - val_loss: 0.0420\n",
      "Training on fashion_mnist with tanh\n",
      "Epoch 1/10\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.8303 - loss: 0.4713 - val_accuracy: 0.8669 - val_loss: 0.3739\n",
      "Epoch 2/10\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.8810 - loss: 0.3273 - val_accuracy: 0.8816 - val_loss: 0.3371\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8968 - loss: 0.2825 - val_accuracy: 0.8896 - val_loss: 0.3068\n",
      "Epoch 4/10\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9086 - loss: 0.2507 - val_accuracy: 0.8927 - val_loss: 0.2916\n",
      "Epoch 5/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9184 - loss: 0.2236 - val_accuracy: 0.8943 - val_loss: 0.2877\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9264 - loss: 0.2010 - val_accuracy: 0.8982 - val_loss: 0.2834\n",
      "Epoch 7/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9346 - loss: 0.1816 - val_accuracy: 0.9004 - val_loss: 0.2808\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9411 - loss: 0.1648 - val_accuracy: 0.8987 - val_loss: 0.2872\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9473 - loss: 0.1488 - val_accuracy: 0.8972 - val_loss: 0.2985\n",
      "Epoch 10/10\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9539 - loss: 0.1340 - val_accuracy: 0.8941 - val_loss: 0.3083\n",
      "Training on cifar10 with tanh\n",
      "Epoch 1/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.4952 - loss: 1.4305 - val_accuracy: 0.5802 - val_loss: 1.1978\n",
      "Epoch 2/10\n",
      "782/782 - 12s - 16ms/step - accuracy: 0.6083 - loss: 1.1184 - val_accuracy: 0.6112 - val_loss: 1.1039\n",
      "Epoch 3/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.6544 - loss: 0.9971 - val_accuracy: 0.6327 - val_loss: 1.0559\n",
      "Epoch 4/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.6846 - loss: 0.9123 - val_accuracy: 0.6441 - val_loss: 1.0361\n",
      "Epoch 5/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7119 - loss: 0.8406 - val_accuracy: 0.6490 - val_loss: 1.0332\n",
      "Epoch 6/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7315 - loss: 0.7812 - val_accuracy: 0.6541 - val_loss: 1.0202\n",
      "Epoch 7/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7550 - loss: 0.7232 - val_accuracy: 0.6458 - val_loss: 1.0628\n",
      "Epoch 8/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7738 - loss: 0.6702 - val_accuracy: 0.6445 - val_loss: 1.1010\n",
      "Epoch 9/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7900 - loss: 0.6218 - val_accuracy: 0.6437 - val_loss: 1.1069\n",
      "Epoch 10/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.8051 - loss: 0.5775 - val_accuracy: 0.6375 - val_loss: 1.1402\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbdd42",
   "metadata": {},
   "source": [
    "## 3. ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed9818d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'relu': 'relu',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efd204",
   "metadata": {},
   "source": [
    "### Training: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc356649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with relu\n",
      "Epoch 1/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9463 - loss: 0.1795 - val_accuracy: 0.9763 - val_loss: 0.0727\n",
      "Epoch 2/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9810 - loss: 0.0646 - val_accuracy: 0.9788 - val_loss: 0.0702\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9837 - loss: 0.0570 - val_accuracy: 0.9778 - val_loss: 0.0808\n",
      "Epoch 4/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9853 - loss: 0.0583 - val_accuracy: 0.9800 - val_loss: 0.0869\n",
      "Epoch 5/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9847 - loss: 0.0743 - val_accuracy: 0.9818 - val_loss: 0.1173\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9840 - loss: 0.0995 - val_accuracy: 0.9752 - val_loss: 0.2276\n",
      "Epoch 7/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9832 - loss: 0.1659 - val_accuracy: 0.9772 - val_loss: 0.3196\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9851 - loss: 0.2068 - val_accuracy: 0.9825 - val_loss: 0.3494\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9836 - loss: 0.3417 - val_accuracy: 0.9746 - val_loss: 0.8016\n",
      "Epoch 10/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9848 - loss: 0.5061 - val_accuracy: 0.9814 - val_loss: 0.9271\n",
      "Training on fashion_mnist with relu\n",
      "Epoch 1/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.8104 - loss: 0.5226 - val_accuracy: 0.8520 - val_loss: 0.4095\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8729 - loss: 0.3568 - val_accuracy: 0.8758 - val_loss: 0.3592\n",
      "Epoch 3/10\n",
      "938/938 - 849s - 905ms/step - accuracy: 0.8838 - loss: 0.3272 - val_accuracy: 0.8807 - val_loss: 0.3498\n",
      "Epoch 4/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8903 - loss: 0.3121 - val_accuracy: 0.8823 - val_loss: 0.3580\n",
      "Epoch 5/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8935 - loss: 0.3080 - val_accuracy: 0.8859 - val_loss: 0.3557\n",
      "Epoch 6/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8941 - loss: 0.3174 - val_accuracy: 0.8788 - val_loss: 0.3910\n",
      "Epoch 7/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8934 - loss: 0.3433 - val_accuracy: 0.8722 - val_loss: 0.4732\n",
      "Epoch 8/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8889 - loss: 0.3988 - val_accuracy: 0.8732 - val_loss: 0.5731\n",
      "Epoch 9/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8845 - loss: 0.4913 - val_accuracy: 0.8744 - val_loss: 0.6534\n",
      "Epoch 10/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.8809 - loss: 0.6103 - val_accuracy: 0.8749 - val_loss: 0.8069\n",
      "Training on cifar10 with relu\n",
      "Epoch 1/10\n",
      "782/782 - 1895s - 2s/step - accuracy: 0.4481 - loss: 1.5369 - val_accuracy: 0.5266 - val_loss: 1.3186\n",
      "Epoch 2/10\n",
      "782/782 - 1833s - 2s/step - accuracy: 0.5719 - loss: 1.2159 - val_accuracy: 0.5962 - val_loss: 1.1487\n",
      "Epoch 3/10\n",
      "782/782 - 238s - 304ms/step - accuracy: 0.6184 - loss: 1.1022 - val_accuracy: 0.6281 - val_loss: 1.0758\n",
      "Epoch 4/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6439 - loss: 1.0319 - val_accuracy: 0.6436 - val_loss: 1.0334\n",
      "Epoch 5/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6533 - loss: 1.0132 - val_accuracy: 0.6465 - val_loss: 1.0454\n",
      "Epoch 6/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6482 - loss: 1.0412 - val_accuracy: 0.6359 - val_loss: 1.1121\n",
      "Epoch 7/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6471 - loss: 1.0757 - val_accuracy: 0.6091 - val_loss: 1.2866\n",
      "Epoch 8/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6335 - loss: 1.1823 - val_accuracy: 0.5617 - val_loss: 1.8172\n",
      "Epoch 9/10\n",
      "782/782 - 13s - 16ms/step - accuracy: 0.6170 - loss: 1.3605 - val_accuracy: 0.5895 - val_loss: 1.5276\n",
      "Epoch 10/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6078 - loss: 1.5066 - val_accuracy: 0.5791 - val_loss: 1.9119\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de843b0f",
   "metadata": {},
   "source": [
    "## 4. SoftPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ce78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'soft_plus': \"softplus\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af772325",
   "metadata": {},
   "source": [
    "### Training: SoftPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c2d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with leaky_relu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-macos-m2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9512 - loss: 0.1662 - val_accuracy: 0.9790 - val_loss: 0.0639\n",
      "Epoch 2/10\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9839 - loss: 0.0512 - val_accuracy: 0.9808 - val_loss: 0.0597\n",
      "Epoch 3/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9887 - loss: 0.0367 - val_accuracy: 0.9834 - val_loss: 0.0535\n",
      "Epoch 4/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9916 - loss: 0.0279 - val_accuracy: 0.9849 - val_loss: 0.0474\n",
      "Epoch 5/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9935 - loss: 0.0215 - val_accuracy: 0.9870 - val_loss: 0.0413\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9948 - loss: 0.0167 - val_accuracy: 0.9888 - val_loss: 0.0396\n",
      "Epoch 7/10\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9960 - loss: 0.0134 - val_accuracy: 0.9873 - val_loss: 0.0490\n",
      "Epoch 8/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9960 - loss: 0.0127 - val_accuracy: 0.9904 - val_loss: 0.0410\n",
      "Epoch 9/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.9896 - val_loss: 0.0409\n",
      "Epoch 10/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9966 - loss: 0.0097 - val_accuracy: 0.9898 - val_loss: 0.0410\n",
      "Training on fashion_mnist with leaky_relu\n",
      "Epoch 1/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.8244 - loss: 0.4851 - val_accuracy: 0.8657 - val_loss: 0.3763\n",
      "Epoch 2/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.8807 - loss: 0.3313 - val_accuracy: 0.8818 - val_loss: 0.3321\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8961 - loss: 0.2887 - val_accuracy: 0.8906 - val_loss: 0.3073\n",
      "Epoch 4/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9058 - loss: 0.2597 - val_accuracy: 0.8956 - val_loss: 0.2939\n",
      "Epoch 5/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9139 - loss: 0.2366 - val_accuracy: 0.8987 - val_loss: 0.2875\n",
      "Epoch 6/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9212 - loss: 0.2171 - val_accuracy: 0.8966 - val_loss: 0.2979\n",
      "Epoch 7/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9281 - loss: 0.1999 - val_accuracy: 0.8957 - val_loss: 0.3143\n",
      "Epoch 8/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9341 - loss: 0.1848 - val_accuracy: 0.8941 - val_loss: 0.3210\n",
      "Epoch 9/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9398 - loss: 0.1702 - val_accuracy: 0.8976 - val_loss: 0.3049\n",
      "Epoch 10/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9442 - loss: 0.1572 - val_accuracy: 0.9044 - val_loss: 0.2892\n",
      "Training on cifar10 with leaky_relu\n",
      "Epoch 1/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.4747 - loss: 1.4701 - val_accuracy: 0.5758 - val_loss: 1.1906\n",
      "Epoch 2/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.6095 - loss: 1.1152 - val_accuracy: 0.6214 - val_loss: 1.0739\n",
      "Epoch 3/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.6601 - loss: 0.9794 - val_accuracy: 0.6426 - val_loss: 1.0180\n",
      "Epoch 4/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.6928 - loss: 0.8892 - val_accuracy: 0.6646 - val_loss: 0.9706\n",
      "Epoch 5/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.7196 - loss: 0.8158 - val_accuracy: 0.6763 - val_loss: 0.9552\n",
      "Epoch 6/10\n",
      "782/782 - 14s - 18ms/step - accuracy: 0.7415 - loss: 0.7546 - val_accuracy: 0.6829 - val_loss: 0.9492\n",
      "Epoch 7/10\n",
      "782/782 - 14s - 18ms/step - accuracy: 0.7622 - loss: 0.6990 - val_accuracy: 0.6844 - val_loss: 0.9654\n",
      "Epoch 8/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.7783 - loss: 0.6505 - val_accuracy: 0.6836 - val_loss: 0.9818\n",
      "Epoch 9/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.7942 - loss: 0.6044 - val_accuracy: 0.6812 - val_loss: 1.0042\n",
      "Epoch 10/10\n",
      "782/782 - 13s - 17ms/step - accuracy: 0.8050 - loss: 0.5674 - val_accuracy: 0.6807 - val_loss: 1.0397\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ac0dd",
   "metadata": {},
   "source": [
    "## 5. Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d386213",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'leaky_relu': tf.keras.layers.LeakyReLU(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7aae5",
   "metadata": {},
   "source": [
    "### Training: Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d3c901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with leaky_relu\n",
      "Epoch 1/10\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9556 - loss: 0.1513 - val_accuracy: 0.9838 - val_loss: 0.0494\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9847 - loss: 0.0500 - val_accuracy: 0.9845 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.9896 - loss: 0.0358 - val_accuracy: 0.9827 - val_loss: 0.0504\n",
      "Epoch 4/10\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.9920 - loss: 0.0268 - val_accuracy: 0.9848 - val_loss: 0.0457\n",
      "Epoch 5/10\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9938 - loss: 0.0207 - val_accuracy: 0.9870 - val_loss: 0.0444\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9948 - loss: 0.0168 - val_accuracy: 0.9882 - val_loss: 0.0394\n",
      "Epoch 7/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9875 - val_loss: 0.0442\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 0.9899 - val_loss: 0.0394\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 0.9889 - val_loss: 0.0414\n",
      "Epoch 10/10\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9969 - loss: 0.0097 - val_accuracy: 0.9879 - val_loss: 0.0474\n",
      "Training on fashion_mnist with leaky_relu\n",
      "Epoch 1/10\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.8265 - loss: 0.4815 - val_accuracy: 0.8667 - val_loss: 0.3704\n",
      "Epoch 2/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8824 - loss: 0.3264 - val_accuracy: 0.8841 - val_loss: 0.3244\n",
      "Epoch 3/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.8972 - loss: 0.2839 - val_accuracy: 0.8919 - val_loss: 0.3083\n",
      "Epoch 4/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9067 - loss: 0.2556 - val_accuracy: 0.8960 - val_loss: 0.2998\n",
      "Epoch 5/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9144 - loss: 0.2327 - val_accuracy: 0.8972 - val_loss: 0.3000\n",
      "Epoch 6/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9222 - loss: 0.2132 - val_accuracy: 0.8955 - val_loss: 0.3066\n",
      "Epoch 7/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9294 - loss: 0.1955 - val_accuracy: 0.8963 - val_loss: 0.3098\n",
      "Epoch 8/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9353 - loss: 0.1798 - val_accuracy: 0.8995 - val_loss: 0.3056\n",
      "Epoch 9/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9405 - loss: 0.1661 - val_accuracy: 0.8998 - val_loss: 0.3139\n",
      "Epoch 10/10\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9457 - loss: 0.1525 - val_accuracy: 0.8991 - val_loss: 0.3179\n",
      "Training on cifar10 with leaky_relu\n",
      "Epoch 1/10\n",
      "782/782 - 15s - 19ms/step - accuracy: 0.4896 - loss: 1.4314 - val_accuracy: 0.5852 - val_loss: 1.1597\n",
      "Epoch 2/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6229 - loss: 1.0808 - val_accuracy: 0.6348 - val_loss: 1.0361\n",
      "Epoch 3/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.6691 - loss: 0.9539 - val_accuracy: 0.6595 - val_loss: 0.9794\n",
      "Epoch 4/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7010 - loss: 0.8650 - val_accuracy: 0.6767 - val_loss: 0.9388\n",
      "Epoch 5/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7274 - loss: 0.7923 - val_accuracy: 0.6895 - val_loss: 0.9165\n",
      "Epoch 6/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7509 - loss: 0.7297 - val_accuracy: 0.6926 - val_loss: 0.9180\n",
      "Epoch 7/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7670 - loss: 0.6777 - val_accuracy: 0.6939 - val_loss: 0.9280\n",
      "Epoch 8/10\n",
      "782/782 - 12s - 16ms/step - accuracy: 0.7832 - loss: 0.6333 - val_accuracy: 0.6938 - val_loss: 0.9430\n",
      "Epoch 9/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.7961 - loss: 0.5940 - val_accuracy: 0.6959 - val_loss: 0.9521\n",
      "Epoch 10/10\n",
      "782/782 - 12s - 15ms/step - accuracy: 0.8100 - loss: 0.5559 - val_accuracy: 0.6976 - val_loss: 0.9793\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94add59",
   "metadata": {},
   "source": [
    "## 6. PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prelu_model(act_config, input_shape=(28, 28, 1)):\n",
    "    \"\"\" \n",
    "    act_config: ignoring input variable\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "\n",
    "    layers.append(tf.keras.layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    layers.append(tf.keras.layers.PReLU()) # directly using prelu\n",
    "    \n",
    "    layers.append(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "    layers.append(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    layers.append(tf.keras.layers.PReLU()) # directly using prelu\n",
    "    \n",
    "    layers.append(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "    layers.append(tf.keras.layers.Flatten())\n",
    "    layers.append(tf.keras.layers.Dense(64))\n",
    "    layers.append(tf.keras.layers.PReLU()) # directly using prelu\n",
    "    \n",
    "    # Output layer - always softmax for classification\n",
    "    layers.append(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbcac665",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'prelu': tf.keras.layers.PReLU(), # this is not a string its a independent layer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fc197",
   "metadata": {},
   "source": [
    "### Training: PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8f3d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with prelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-macos-m2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 31s - 33ms/step - accuracy: 0.9438 - loss: 0.1881 - val_accuracy: 0.9762 - val_loss: 0.0726\n",
      "Epoch 2/10\n",
      "938/938 - 21s - 22ms/step - accuracy: 0.9829 - loss: 0.0547 - val_accuracy: 0.9859 - val_loss: 0.0438\n",
      "Epoch 3/10\n",
      "938/938 - 20s - 22ms/step - accuracy: 0.9885 - loss: 0.0371 - val_accuracy: 0.9853 - val_loss: 0.0432\n",
      "Epoch 4/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9917 - loss: 0.0274 - val_accuracy: 0.9850 - val_loss: 0.0450\n",
      "Epoch 5/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9940 - loss: 0.0202 - val_accuracy: 0.9884 - val_loss: 0.0396\n",
      "Epoch 6/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.9896 - val_loss: 0.0347\n",
      "Epoch 7/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9961 - loss: 0.0126 - val_accuracy: 0.9905 - val_loss: 0.0351\n",
      "Epoch 8/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9890 - val_loss: 0.0456\n",
      "Epoch 9/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9965 - loss: 0.0100 - val_accuracy: 0.9905 - val_loss: 0.0396\n",
      "Epoch 10/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9889 - val_loss: 0.0415\n",
      "Training on fashion_mnist with prelu\n",
      "Epoch 1/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.8172 - loss: 0.5087 - val_accuracy: 0.8589 - val_loss: 0.3960\n",
      "Epoch 2/10\n",
      "938/938 - 20s - 22ms/step - accuracy: 0.8799 - loss: 0.3331 - val_accuracy: 0.8826 - val_loss: 0.3368\n",
      "Epoch 3/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.8955 - loss: 0.2867 - val_accuracy: 0.8939 - val_loss: 0.3014\n",
      "Epoch 4/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9071 - loss: 0.2553 - val_accuracy: 0.8990 - val_loss: 0.2866\n",
      "Epoch 5/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9162 - loss: 0.2296 - val_accuracy: 0.9027 - val_loss: 0.2760\n",
      "Epoch 6/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9253 - loss: 0.2069 - val_accuracy: 0.9050 - val_loss: 0.2691\n",
      "Epoch 7/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9325 - loss: 0.1864 - val_accuracy: 0.9049 - val_loss: 0.2741\n",
      "Epoch 8/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9403 - loss: 0.1680 - val_accuracy: 0.9054 - val_loss: 0.2763\n",
      "Epoch 9/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9468 - loss: 0.1501 - val_accuracy: 0.9049 - val_loss: 0.2959\n",
      "Epoch 10/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9516 - loss: 0.1358 - val_accuracy: 0.9026 - val_loss: 0.3245\n",
      "Training on cifar10 with prelu\n",
      "Epoch 1/10\n",
      "782/782 - 26s - 33ms/step - accuracy: 0.4531 - loss: 1.5209 - val_accuracy: 0.5625 - val_loss: 1.2380\n",
      "Epoch 2/10\n",
      "782/782 - 19s - 24ms/step - accuracy: 0.5907 - loss: 1.1640 - val_accuracy: 0.6207 - val_loss: 1.1022\n",
      "Epoch 3/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.6458 - loss: 1.0131 - val_accuracy: 0.6438 - val_loss: 1.0223\n",
      "Epoch 4/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.6840 - loss: 0.9094 - val_accuracy: 0.6597 - val_loss: 0.9816\n",
      "Epoch 5/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.7128 - loss: 0.8297 - val_accuracy: 0.6752 - val_loss: 0.9439\n",
      "Epoch 6/10\n",
      "782/782 - 18s - 24ms/step - accuracy: 0.7394 - loss: 0.7582 - val_accuracy: 0.6836 - val_loss: 0.9422\n",
      "Epoch 7/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.7617 - loss: 0.6959 - val_accuracy: 0.6895 - val_loss: 0.9381\n",
      "Epoch 8/10\n",
      "782/782 - 18s - 24ms/step - accuracy: 0.7824 - loss: 0.6379 - val_accuracy: 0.6823 - val_loss: 0.9781\n",
      "Epoch 9/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.8012 - loss: 0.5835 - val_accuracy: 0.6722 - val_loss: 1.0404\n",
      "Epoch 10/10\n",
      "782/782 - 18s - 23ms/step - accuracy: 0.8168 - loss: 0.5357 - val_accuracy: 0.6623 - val_loss: 1.1016\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_prelu_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6181c47",
   "metadata": {},
   "source": [
    "## 7. ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83ff1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'elu': \"elu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a92ede",
   "metadata": {},
   "source": [
    "### Training: ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f9069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with elu\n",
      "Epoch 1/10\n",
      "938/938 - 26s - 28ms/step - accuracy: 0.9550 - loss: 0.1531 - val_accuracy: 0.9776 - val_loss: 0.0686\n",
      "Epoch 2/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9840 - loss: 0.0510 - val_accuracy: 0.9818 - val_loss: 0.0584\n",
      "Epoch 3/10\n",
      "938/938 - 23s - 24ms/step - accuracy: 0.9898 - loss: 0.0344 - val_accuracy: 0.9842 - val_loss: 0.0533\n",
      "Epoch 4/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9932 - loss: 0.0238 - val_accuracy: 0.9854 - val_loss: 0.0491\n",
      "Epoch 5/10\n",
      "938/938 - 23s - 25ms/step - accuracy: 0.9948 - loss: 0.0180 - val_accuracy: 0.9868 - val_loss: 0.0492\n",
      "Epoch 6/10\n",
      "938/938 - 23s - 24ms/step - accuracy: 0.9958 - loss: 0.0140 - val_accuracy: 0.9891 - val_loss: 0.0397\n",
      "Epoch 7/10\n",
      "938/938 - 21s - 23ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.9896 - val_loss: 0.0392\n",
      "Epoch 8/10\n",
      "938/938 - 22s - 24ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9903 - val_loss: 0.0424\n",
      "Epoch 9/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.9895 - val_loss: 0.0443\n",
      "Epoch 10/10\n",
      "938/938 - 23s - 25ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9897 - val_loss: 0.0416\n",
      "Training on fashion_mnist with elu\n",
      "Epoch 1/10\n",
      "938/938 - 26s - 27ms/step - accuracy: 0.8314 - loss: 0.4691 - val_accuracy: 0.8700 - val_loss: 0.3626\n",
      "Epoch 2/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.8846 - loss: 0.3186 - val_accuracy: 0.8846 - val_loss: 0.3214\n",
      "Epoch 3/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.8998 - loss: 0.2748 - val_accuracy: 0.8911 - val_loss: 0.3016\n",
      "Epoch 4/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9115 - loss: 0.2432 - val_accuracy: 0.8956 - val_loss: 0.2918\n",
      "Epoch 5/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9214 - loss: 0.2166 - val_accuracy: 0.8991 - val_loss: 0.2882\n",
      "Epoch 6/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9301 - loss: 0.1925 - val_accuracy: 0.9013 - val_loss: 0.2917\n",
      "Epoch 7/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.9380 - loss: 0.1709 - val_accuracy: 0.9042 - val_loss: 0.2957\n",
      "Epoch 8/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.9454 - loss: 0.1509 - val_accuracy: 0.9057 - val_loss: 0.3000\n",
      "Epoch 9/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9533 - loss: 0.1322 - val_accuracy: 0.9065 - val_loss: 0.3118\n",
      "Epoch 10/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9599 - loss: 0.1155 - val_accuracy: 0.9056 - val_loss: 0.3399\n",
      "Training on cifar10 with elu\n",
      "Epoch 1/10\n",
      "782/782 - 28s - 35ms/step - accuracy: 0.5019 - loss: 1.4117 - val_accuracy: 0.5898 - val_loss: 1.1744\n",
      "Epoch 2/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.6145 - loss: 1.0994 - val_accuracy: 0.6320 - val_loss: 1.0559\n",
      "Epoch 3/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.6609 - loss: 0.9723 - val_accuracy: 0.6467 - val_loss: 1.0125\n",
      "Epoch 4/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.6991 - loss: 0.8742 - val_accuracy: 0.6595 - val_loss: 1.0002\n",
      "Epoch 5/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.7271 - loss: 0.7923 - val_accuracy: 0.6692 - val_loss: 0.9934\n",
      "Epoch 6/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.7523 - loss: 0.7204 - val_accuracy: 0.6769 - val_loss: 1.0008\n",
      "Epoch 7/10\n",
      "782/782 - 24s - 30ms/step - accuracy: 0.7757 - loss: 0.6529 - val_accuracy: 0.6788 - val_loss: 1.0294\n",
      "Epoch 8/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.7973 - loss: 0.5920 - val_accuracy: 0.6765 - val_loss: 1.0696\n",
      "Epoch 9/10\n",
      "782/782 - 22s - 29ms/step - accuracy: 0.8187 - loss: 0.5364 - val_accuracy: 0.6657 - val_loss: 1.1221\n",
      "Epoch 10/10\n",
      "782/782 - 22s - 28ms/step - accuracy: 0.8360 - loss: 0.4863 - val_accuracy: 0.6530 - val_loss: 1.2403\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e083d",
   "metadata": {},
   "source": [
    "## 8. GELU (Gaussian Error Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f1ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'gelu': tf.keras.activations.gelu,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273206a2",
   "metadata": {},
   "source": [
    "### Training: GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e53cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with gelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-macos-m2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 21s - 23ms/step - accuracy: 0.9441 - loss: 0.1855 - val_accuracy: 0.9765 - val_loss: 0.0706\n",
      "Epoch 2/10\n",
      "938/938 - 19s - 20ms/step - accuracy: 0.9843 - loss: 0.0518 - val_accuracy: 0.9834 - val_loss: 0.0533\n",
      "Epoch 3/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9898 - loss: 0.0336 - val_accuracy: 0.9845 - val_loss: 0.0468\n",
      "Epoch 4/10\n",
      "938/938 - 18s - 20ms/step - accuracy: 0.9931 - loss: 0.0233 - val_accuracy: 0.9885 - val_loss: 0.0375\n",
      "Epoch 5/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9955 - loss: 0.0162 - val_accuracy: 0.9876 - val_loss: 0.0372\n",
      "Epoch 6/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.9886 - val_loss: 0.0406\n",
      "Epoch 7/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.9891 - val_loss: 0.0417\n",
      "Epoch 8/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.9899 - val_loss: 0.0390\n",
      "Epoch 9/10\n",
      "938/938 - 18s - 20ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9891 - val_loss: 0.0401\n",
      "Epoch 10/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9894 - val_loss: 0.0440\n",
      "Training on fashion_mnist with gelu\n",
      "Epoch 1/10\n",
      "938/938 - 21s - 23ms/step - accuracy: 0.8081 - loss: 0.5257 - val_accuracy: 0.8554 - val_loss: 0.4051\n",
      "Epoch 2/10\n",
      "938/938 - 19s - 20ms/step - accuracy: 0.8716 - loss: 0.3500 - val_accuracy: 0.8763 - val_loss: 0.3458\n",
      "Epoch 3/10\n",
      "938/938 - 19s - 20ms/step - accuracy: 0.8894 - loss: 0.3014 - val_accuracy: 0.8841 - val_loss: 0.3171\n",
      "Epoch 4/10\n",
      "938/938 - 18s - 20ms/step - accuracy: 0.9012 - loss: 0.2687 - val_accuracy: 0.8931 - val_loss: 0.2974\n",
      "Epoch 5/10\n",
      "938/938 - 19s - 20ms/step - accuracy: 0.9114 - loss: 0.2426 - val_accuracy: 0.8974 - val_loss: 0.2842\n",
      "Epoch 6/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9187 - loss: 0.2194 - val_accuracy: 0.9021 - val_loss: 0.2787\n",
      "Epoch 7/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9271 - loss: 0.1980 - val_accuracy: 0.9021 - val_loss: 0.2831\n",
      "Epoch 8/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9345 - loss: 0.1783 - val_accuracy: 0.9016 - val_loss: 0.2896\n",
      "Epoch 9/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9418 - loss: 0.1599 - val_accuracy: 0.9021 - val_loss: 0.2917\n",
      "Epoch 10/10\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9487 - loss: 0.1427 - val_accuracy: 0.9038 - val_loss: 0.2993\n",
      "Training on cifar10 with gelu\n",
      "Epoch 1/10\n",
      "782/782 - 22s - 28ms/step - accuracy: 0.4703 - loss: 1.4895 - val_accuracy: 0.5660 - val_loss: 1.2342\n",
      "Epoch 2/10\n",
      "782/782 - 17s - 21ms/step - accuracy: 0.6040 - loss: 1.1228 - val_accuracy: 0.6292 - val_loss: 1.0636\n",
      "Epoch 3/10\n",
      "782/782 - 17s - 21ms/step - accuracy: 0.6598 - loss: 0.9703 - val_accuracy: 0.6463 - val_loss: 1.0046\n",
      "Epoch 4/10\n",
      "782/782 - 16s - 21ms/step - accuracy: 0.6992 - loss: 0.8634 - val_accuracy: 0.6606 - val_loss: 0.9816\n",
      "Epoch 5/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.7318 - loss: 0.7761 - val_accuracy: 0.6684 - val_loss: 0.9834\n",
      "Epoch 6/10\n",
      "782/782 - 17s - 21ms/step - accuracy: 0.7583 - loss: 0.7005 - val_accuracy: 0.6632 - val_loss: 1.0170\n",
      "Epoch 7/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.7818 - loss: 0.6329 - val_accuracy: 0.6686 - val_loss: 1.0290\n",
      "Epoch 8/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.8053 - loss: 0.5673 - val_accuracy: 0.6719 - val_loss: 1.0690\n",
      "Epoch 9/10\n",
      "782/782 - 17s - 22ms/step - accuracy: 0.8309 - loss: 0.5022 - val_accuracy: 0.6736 - val_loss: 1.1282\n",
      "Epoch 10/10\n",
      "782/782 - 17s - 21ms/step - accuracy: 0.8510 - loss: 0.4447 - val_accuracy: 0.6678 - val_loss: 1.2045\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea902d8b",
   "metadata": {},
   "source": [
    "## 9. Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03345c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'swish': tf.keras.activations.swish,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43970c",
   "metadata": {},
   "source": [
    "### Training: Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfbdae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with swish\n",
      "Epoch 1/10\n",
      "938/938 - 27s - 29ms/step - accuracy: 0.9468 - loss: 0.1831 - val_accuracy: 0.9807 - val_loss: 0.0598\n",
      "Epoch 2/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9850 - loss: 0.0491 - val_accuracy: 0.9832 - val_loss: 0.0554\n",
      "Epoch 3/10\n",
      "938/938 - 16s - 17ms/step - accuracy: 0.9901 - loss: 0.0329 - val_accuracy: 0.9868 - val_loss: 0.0454\n",
      "Epoch 4/10\n",
      "938/938 - 16s - 18ms/step - accuracy: 0.9931 - loss: 0.0232 - val_accuracy: 0.9893 - val_loss: 0.0352\n",
      "Epoch 5/10\n",
      "938/938 - 16s - 18ms/step - accuracy: 0.9954 - loss: 0.0163 - val_accuracy: 0.9896 - val_loss: 0.0400\n",
      "Epoch 6/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9963 - loss: 0.0128 - val_accuracy: 0.9907 - val_loss: 0.0360\n",
      "Epoch 7/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.9902 - val_loss: 0.0373\n",
      "Epoch 8/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9909 - val_loss: 0.0388\n",
      "Epoch 9/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.9922 - val_loss: 0.0327\n",
      "Epoch 10/10\n",
      "938/938 - 16s - 17ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9904 - val_loss: 0.0382\n",
      "Training on fashion_mnist with swish\n",
      "Epoch 1/10\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.8088 - loss: 0.5222 - val_accuracy: 0.8536 - val_loss: 0.4039\n",
      "Epoch 2/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.8726 - loss: 0.3481 - val_accuracy: 0.8718 - val_loss: 0.3497\n",
      "Epoch 3/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.8883 - loss: 0.3009 - val_accuracy: 0.8813 - val_loss: 0.3239\n",
      "Epoch 4/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9006 - loss: 0.2698 - val_accuracy: 0.8881 - val_loss: 0.3114\n",
      "Epoch 5/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9093 - loss: 0.2452 - val_accuracy: 0.8907 - val_loss: 0.3059\n",
      "Epoch 6/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9172 - loss: 0.2237 - val_accuracy: 0.8941 - val_loss: 0.2991\n",
      "Epoch 7/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9245 - loss: 0.2037 - val_accuracy: 0.8966 - val_loss: 0.2947\n",
      "Epoch 8/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9321 - loss: 0.1847 - val_accuracy: 0.8984 - val_loss: 0.2984\n",
      "Epoch 9/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9392 - loss: 0.1667 - val_accuracy: 0.8985 - val_loss: 0.3065\n",
      "Epoch 10/10\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9452 - loss: 0.1497 - val_accuracy: 0.8976 - val_loss: 0.3177\n",
      "Training on cifar10 with swish\n",
      "Epoch 1/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.4553 - loss: 1.5246 - val_accuracy: 0.5522 - val_loss: 1.2512\n",
      "Epoch 2/10\n",
      "782/782 - 16s - 20ms/step - accuracy: 0.5946 - loss: 1.1523 - val_accuracy: 0.6133 - val_loss: 1.0993\n",
      "Epoch 3/10\n",
      "782/782 - 15s - 20ms/step - accuracy: 0.6529 - loss: 0.9967 - val_accuracy: 0.6393 - val_loss: 1.0475\n",
      "Epoch 4/10\n",
      "782/782 - 15s - 20ms/step - accuracy: 0.6889 - loss: 0.8953 - val_accuracy: 0.6590 - val_loss: 0.9949\n",
      "Epoch 5/10\n",
      "782/782 - 16s - 20ms/step - accuracy: 0.7171 - loss: 0.8155 - val_accuracy: 0.6689 - val_loss: 0.9691\n",
      "Epoch 6/10\n",
      "782/782 - 15s - 20ms/step - accuracy: 0.7424 - loss: 0.7459 - val_accuracy: 0.6700 - val_loss: 0.9814\n",
      "Epoch 7/10\n",
      "782/782 - 15s - 19ms/step - accuracy: 0.7643 - loss: 0.6834 - val_accuracy: 0.6603 - val_loss: 1.0411\n",
      "Epoch 8/10\n",
      "782/782 - 15s - 19ms/step - accuracy: 0.7859 - loss: 0.6277 - val_accuracy: 0.6654 - val_loss: 1.0560\n",
      "Epoch 9/10\n",
      "782/782 - 15s - 20ms/step - accuracy: 0.8026 - loss: 0.5767 - val_accuracy: 0.6667 - val_loss: 1.0936\n",
      "Epoch 10/10\n",
      "782/782 - 15s - 19ms/step - accuracy: 0.8216 - loss: 0.5238 - val_accuracy: 0.6654 - val_loss: 1.1595\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b584ee",
   "metadata": {},
   "source": [
    "## 10. Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58777c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_configs = {\n",
    "    'mish': tf.keras.activations.mish,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c13d0",
   "metadata": {},
   "source": [
    "### Training: Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "739dbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mnist with mish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-macos-m2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 28s - 29ms/step - accuracy: 0.9497 - loss: 0.1693 - val_accuracy: 0.9801 - val_loss: 0.0601\n",
      "Epoch 2/10\n",
      "938/938 - 29s - 31ms/step - accuracy: 0.9851 - loss: 0.0490 - val_accuracy: 0.9840 - val_loss: 0.0510\n",
      "Epoch 3/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.9902 - loss: 0.0323 - val_accuracy: 0.9834 - val_loss: 0.0515\n",
      "Epoch 4/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.9935 - loss: 0.0222 - val_accuracy: 0.9873 - val_loss: 0.0423\n",
      "Epoch 5/10\n",
      "938/938 - 23s - 25ms/step - accuracy: 0.9951 - loss: 0.0165 - val_accuracy: 0.9900 - val_loss: 0.0379\n",
      "Epoch 6/10\n",
      "938/938 - 22s - 24ms/step - accuracy: 0.9963 - loss: 0.0122 - val_accuracy: 0.9891 - val_loss: 0.0426\n",
      "Epoch 7/10\n",
      "938/938 - 23s - 24ms/step - accuracy: 0.9967 - loss: 0.0103 - val_accuracy: 0.9903 - val_loss: 0.0353\n",
      "Epoch 8/10\n",
      "938/938 - 26s - 28ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9897 - val_loss: 0.0409\n",
      "Epoch 9/10\n",
      "938/938 - 24s - 26ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9909 - val_loss: 0.0383\n",
      "Epoch 10/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9894 - val_loss: 0.0445\n",
      "Training on fashion_mnist with mish\n",
      "Epoch 1/10\n",
      "938/938 - 26s - 27ms/step - accuracy: 0.8119 - loss: 0.5130 - val_accuracy: 0.8538 - val_loss: 0.3929\n",
      "Epoch 2/10\n",
      "938/938 - 23s - 24ms/step - accuracy: 0.8750 - loss: 0.3420 - val_accuracy: 0.8760 - val_loss: 0.3394\n",
      "Epoch 3/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.8918 - loss: 0.2933 - val_accuracy: 0.8876 - val_loss: 0.3166\n",
      "Epoch 4/10\n",
      "938/938 - 22s - 24ms/step - accuracy: 0.9040 - loss: 0.2615 - val_accuracy: 0.8920 - val_loss: 0.3052\n",
      "Epoch 5/10\n",
      "938/938 - 22s - 23ms/step - accuracy: 0.9130 - loss: 0.2368 - val_accuracy: 0.8969 - val_loss: 0.2975\n",
      "Epoch 6/10\n",
      "938/938 - 23s - 24ms/step - accuracy: 0.9204 - loss: 0.2147 - val_accuracy: 0.8993 - val_loss: 0.2910\n",
      "Epoch 7/10\n",
      "938/938 - 25s - 26ms/step - accuracy: 0.9283 - loss: 0.1939 - val_accuracy: 0.9006 - val_loss: 0.2868\n",
      "Epoch 8/10\n",
      "938/938 - 25s - 27ms/step - accuracy: 0.9361 - loss: 0.1746 - val_accuracy: 0.9033 - val_loss: 0.2886\n",
      "Epoch 9/10\n",
      "938/938 - 24s - 25ms/step - accuracy: 0.9427 - loss: 0.1573 - val_accuracy: 0.9036 - val_loss: 0.2972\n",
      "Epoch 10/10\n",
      "938/938 - 23s - 25ms/step - accuracy: 0.9488 - loss: 0.1414 - val_accuracy: 0.9036 - val_loss: 0.3144\n",
      "Training on cifar10 with mish\n",
      "Epoch 1/10\n",
      "782/782 - 40s - 51ms/step - accuracy: 0.4782 - loss: 1.4695 - val_accuracy: 0.5709 - val_loss: 1.2174\n",
      "Epoch 2/10\n",
      "782/782 - 24s - 31ms/step - accuracy: 0.6108 - loss: 1.1086 - val_accuracy: 0.6215 - val_loss: 1.0816\n",
      "Epoch 3/10\n",
      "782/782 - 25s - 31ms/step - accuracy: 0.6651 - loss: 0.9587 - val_accuracy: 0.6492 - val_loss: 1.0258\n",
      "Epoch 4/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.7020 - loss: 0.8556 - val_accuracy: 0.6644 - val_loss: 0.9997\n",
      "Epoch 5/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.7301 - loss: 0.7748 - val_accuracy: 0.6697 - val_loss: 0.9824\n",
      "Epoch 6/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.7575 - loss: 0.7036 - val_accuracy: 0.6775 - val_loss: 0.9880\n",
      "Epoch 7/10\n",
      "782/782 - 23s - 30ms/step - accuracy: 0.7819 - loss: 0.6385 - val_accuracy: 0.6774 - val_loss: 1.0249\n",
      "Epoch 8/10\n",
      "782/782 - 24s - 31ms/step - accuracy: 0.8008 - loss: 0.5806 - val_accuracy: 0.6756 - val_loss: 1.0708\n",
      "Epoch 9/10\n",
      "782/782 - 23s - 30ms/step - accuracy: 0.8194 - loss: 0.5262 - val_accuracy: 0.6749 - val_loss: 1.1451\n",
      "Epoch 10/10\n",
      "782/782 - 23s - 29ms/step - accuracy: 0.8402 - loss: 0.4721 - val_accuracy: 0.6688 - val_loss: 1.2112\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loop with TensorBoard Logging\n",
    "for dataset_name, loader in datasets.items():\n",
    "    (x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    else:\n",
    "        x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "        x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    for act_name, act_config in activation_configs.items():\n",
    "        print(f\"Training on {dataset_name} with {act_name}\")\n",
    "\n",
    "        model = create_model(activation_configs[act_name], input_shape=x_train.shape[1:])\n",
    "        log_dir = f\"logs/{dataset_name}/{act_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(f\"models/{dataset_name}_{act_name}.keras\", save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks=[tb_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179cf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef88997",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f43f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! find logs/ | grep tfevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f4e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing event files... (this can take a few minutes)\n",
      "======================================================================\n",
      "\n",
      "Found event files in:\n",
      "logs/mnist/leaky_relu/20250516-101650/train\n",
      "logs/mnist/leaky_relu/20250516-101650/validation\n",
      "logs/mnist/tanh/20250516-101232/train\n",
      "logs/mnist/tanh/20250516-101232/validation\n",
      "logs/mnist/relu/20250516-101442/train\n",
      "logs/mnist/relu/20250516-101442/validation\n",
      "logs/mnist/sigmoid/20250516-101022/train\n",
      "logs/mnist/sigmoid/20250516-101022/validation\n",
      "logs/mnist/elu/20250516-101901/train\n",
      "logs/mnist/elu/20250516-101901/validation\n",
      "logs/mnist/swish/20250516-102234/train\n",
      "logs/mnist/swish/20250516-102234/validation\n",
      "logs/fashion_mnist/leaky_relu/20250516-103216/train\n",
      "logs/fashion_mnist/leaky_relu/20250516-103216/validation\n",
      "logs/fashion_mnist/tanh/20250516-102722/train\n",
      "logs/fashion_mnist/tanh/20250516-102722/validation\n",
      "logs/fashion_mnist/relu/20250516-102933/train\n",
      "logs/fashion_mnist/relu/20250516-102933/validation\n",
      "logs/fashion_mnist/sigmoid/20250516-102509/train\n",
      "logs/fashion_mnist/sigmoid/20250516-102509/validation\n",
      "logs/fashion_mnist/elu/20250516-103428/train\n",
      "logs/fashion_mnist/elu/20250516-103428/validation\n",
      "logs/fashion_mnist/swish/20250516-104614/train\n",
      "logs/fashion_mnist/swish/20250516-104614/validation\n",
      "logs/cifar10/leaky_relu/20250516-105522/train\n",
      "logs/cifar10/leaky_relu/20250516-105522/validation\n",
      "logs/cifar10/tanh/20250516-105104/train\n",
      "logs/cifar10/tanh/20250516-105104/validation\n",
      "logs/cifar10/relu/20250516-105316/train\n",
      "logs/cifar10/relu/20250516-105316/validation\n",
      "logs/cifar10/sigmoid/20250516-104855/train\n",
      "logs/cifar10/sigmoid/20250516-104855/validation\n",
      "logs/cifar10/elu/20250516-105731/train\n",
      "logs/cifar10/elu/20250516-105731/validation\n",
      "logs/cifar10/swish/20250516-110722/train\n",
      "logs/cifar10/swish/20250516-110722/validation\n",
      "\n",
      "These tags are in logs/mnist/leaky_relu/20250516-101650/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/leaky_relu/20250516-101650/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/leaky_relu/20250516-101650/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/leaky_relu/20250516-101650/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/tanh/20250516-101232/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/tanh/20250516-101232/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/tanh/20250516-101232/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/tanh/20250516-101232/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/relu/20250516-101442/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/relu/20250516-101442/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/relu/20250516-101442/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/relu/20250516-101442/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/sigmoid/20250516-101022/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/sigmoid/20250516-101022/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/sigmoid/20250516-101022/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/sigmoid/20250516-101022/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/elu/20250516-101901/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/elu/20250516-101901/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/elu/20250516-101901/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/elu/20250516-101901/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/swish/20250516-102234/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/swish/20250516-102234/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/mnist/swish/20250516-102234/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/mnist/swish/20250516-102234/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/leaky_relu/20250516-103216/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/leaky_relu/20250516-103216/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/leaky_relu/20250516-103216/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/leaky_relu/20250516-103216/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/tanh/20250516-102722/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/tanh/20250516-102722/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/tanh/20250516-102722/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/tanh/20250516-102722/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/relu/20250516-102933/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/relu/20250516-102933/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/relu/20250516-102933/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/relu/20250516-102933/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/sigmoid/20250516-102509/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/sigmoid/20250516-102509/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/sigmoid/20250516-102509/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/sigmoid/20250516-102509/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/elu/20250516-103428/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/elu/20250516-103428/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/elu/20250516-103428/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/elu/20250516-103428/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/swish/20250516-104614/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/swish/20250516-104614/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/fashion_mnist/swish/20250516-104614/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/fashion_mnist/swish/20250516-104614/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           938\n",
      "   last_step            9\n",
      "   max_step             9380\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(938, 0), (1876, 1), (2814, 2), (3752, 3), (4690, 4), (5628, 5), (6566, 6), (7504, 7), (8442, 8), (9380, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/leaky_relu/20250516-105522/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/leaky_relu/20250516-105522/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/leaky_relu/20250516-105522/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/leaky_relu/20250516-105522/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/tanh/20250516-105104/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/tanh/20250516-105104/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/tanh/20250516-105104/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/tanh/20250516-105104/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/relu/20250516-105316/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/relu/20250516-105316/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/relu/20250516-105316/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/relu/20250516-105316/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/sigmoid/20250516-104855/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/sigmoid/20250516-104855/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/sigmoid/20250516-104855/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/sigmoid/20250516-104855/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/elu/20250516-105731/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/elu/20250516-105731/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/elu/20250516-105731/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/elu/20250516-105731/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/swish/20250516-110722/train:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   bias/histogram\n",
      "   epoch_accuracy\n",
      "   epoch_learning_rate\n",
      "   epoch_loss\n",
      "   keras\n",
      "   kernel/histogram\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/swish/20250516-110722/train:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           0\n",
      "   last_step            9\n",
      "   max_step             9\n",
      "   min_step             0\n",
      "   num_steps            10\n",
      "   outoforder_steps     []\n",
      "======================================================================\n",
      "\n",
      "These tags are in logs/cifar10/swish/20250516-110722/validation:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "tensor\n",
      "   epoch_accuracy\n",
      "   epoch_loss\n",
      "   evaluation_accuracy_vs_iterations\n",
      "   evaluation_loss_vs_iterations\n",
      "======================================================================\n",
      "\n",
      "Event statistics for logs/cifar10/swish/20250516-110722/validation:\n",
      "audio -\n",
      "graph -\n",
      "histograms -\n",
      "images -\n",
      "scalars -\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor\n",
      "   first_step           782\n",
      "   last_step            9\n",
      "   max_step             7820\n",
      "   min_step             0\n",
      "   num_steps            20\n",
      "   outoforder_steps     [(782, 0), (1564, 1), (2346, 2), (3128, 3), (3910, 4), (4692, 5), (5474, 6), (6256, 7), (7038, 8), (7820, 9)]\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --inspect --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "369e38b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Hands-on DL/activation-wars'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a1c769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=logs/cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45354d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-macos-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
